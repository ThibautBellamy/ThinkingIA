# Installation : pip install transformers torch sentence-transformers
from transformers import AutoModel, AutoTokenizer
import torch
import numpy as np
import sys

class BaseModeleFrancais:
    """
    Mod√®le de base fran√ßais - Fondation pour nos h√©misph√®res
    """
    def __init__(self):
        # CamemBERT : le BERT fran√ßais l√©ger et performant
        self.model_name = "camembert-base"
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModel.from_pretrained(self.model_name)
        
        print("üá´üá∑ Mod√®le fran√ßais charg√© avec succ√®s !")
        print(f"üìä Vocabulaire : {self.tokenizer.vocab_size} mots")
        print(f"üîß Param√®tres : ~110M")
    
    def encoder_texte(self, texte):
        """
        Encode un texte fran√ßais en repr√©sentation vectorielle
        C'est la base de la compr√©hension linguistique
        """
        inputs = self.tokenizer(
            texte, 
            return_tensors="pt", 
            padding=True, 
            truncation=True,
            max_length=512
        )
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            # Moyenne des tokens pour avoir une repr√©sentation du texte complet
            embeddings = outputs.last_hidden_state.mean(dim=1)
        
        return embeddings.numpy()
    
    def similarite_semantique(self, texte1, texte2):
        """
        Calcule la similarit√© s√©mantique entre deux textes
        Utile pour la compr√©hension contextuelle
        """
        emb1 = self.encoder_texte(texte1)
        emb2 = self.encoder_texte(texte2)
        
        # Cosine similarity
        similarity = np.dot(emb1, emb2.T) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))
        return float(similarity[0][0])
    
    def analyser_phrase(self, phrase):
        """
        Analyse basique d'une phrase fran√ßaise
        Premier pas vers la compr√©hension logique
        """
        # Tokenisation pour voir comment le mod√®le d√©compose
        tokens = self.tokenizer.tokenize(phrase)
        
        # Encoding pour obtenir la repr√©sentation vectorielle
        encoding = self.encoder_texte(phrase)
        
        return {
            'tokens': tokens,
            'nombre_tokens': len(tokens),
            'representation_vectorielle': encoding,
            'taille_representation': encoding.shape
        }
    
    def test_comprehension(self):
        """
        Test rapide pour v√©rifier que le mod√®le comprend le fran√ßais
        """
        print("\nüß™ Test de compr√©hension fran√ßaise...")
        
        phrases_test = [
            "Le chat mange une souris",
            "Einstein √©tait un g√©nie",
            "2 + 2 = 4",
            "Je pense donc je suis"
        ]
        
        for phrase in phrases_test:
            analyse = self.analyser_phrase(phrase)
            print(f"üìù '{phrase}' -> {analyse['nombre_tokens']} tokens")
        
        # Test de similarit√© s√©mantique
        sim = self.similarite_semantique(
            "Le chat mange", 
            "L'animal se nourrit"
        )
        print(f"üîç Similarit√© s√©mantique : {sim:.3f}")
        print("‚úÖ Mod√®le fran√ßais op√©rationnel !")

    def tester_comprehension_interactive(self):
        """
        Mode interactif pour tester la compr√©hension du mod√®le
        """
        print("\nüß† Mode test de compr√©hension - Tapez 'quitter' pour arr√™ter")
        print("üí° Le mod√®le va analyser ce que vous dites mais ne peut pas r√©pondre directement")
        
        while True:
            user_input = input("\nVous: ").strip()
            
            if user_input.lower() in ['quitter', 'exit', 'stop']:
                print("Test termin√© !")
                break
            
            # Analyse de la phrase
            analyse = self.analyser_phrase(user_input)
            print(f"üîç Analyse: {analyse['nombre_tokens']} tokens")
            print(f"üìù Tokens: {analyse['tokens'][:10]}...")  # Affiche les 10 premiers
            
            # Test de compr√©hension avec des phrases de r√©f√©rence
            phrases_reference = [
                "C'est une question",
                "C'est une affirmation", 
                "C'est une salutation",
                "C'est du contenu math√©matique",
                "C'est de la philosophie",
                "C'est de la science"
            ]
            
            print("üìä Le mod√®le pense que c'est closest √† :")
            scores = []
            for ref in phrases_reference:
                score = self.similarite_semantique(user_input, ref)
                scores.append((ref, score))
            
            # Trier par score descendant
            scores.sort(key=lambda x: x[1], reverse=True)
            
            for i, (ref, score) in enumerate(scores[:3]):
                print(f"  {i+1}. {ref} (score: {score:.3f})")

    def chat_simule(self):
        """
        Chat simul√© : le mod√®le choisit la r√©ponse la plus appropri√©e
        bas√©e sur la compr√©hension s√©mantique
        """
        print("\nü§ñ Mode chat simul√© - Le mod√®le va 'r√©pondre' par similarit√©")
        
        # Base de r√©ponses avec contextes
        base_reponses = {
            "salutations": [
                "Bonjour ! Comment allez-vous ?",
                "Salut ! Que puis-je analyser pour vous ?"
            ],
            "questions_logique": [
                "C'est un probl√®me logique int√©ressant.",
                "Laissez-moi analyser cette proposition."
            ],
            "mathematiques": [
                "Je vois des √©l√©ments math√©matiques ici.",
                "C'est du calcul ou de la logique num√©rique."
            ],
            "philosophie": [
                "Voil√† une r√©flexion philosophique profonde.",
                "Cette question touche aux concepts abstraits."
            ],
            "incomprehension": [
                "Je n'ai pas assez de contexte pour analyser cela.",
                "Pouvez-vous reformuler diff√©remment ?"
            ]
        }
        
        while True:
            user_input = input("\nVous: ").strip()
            
            if user_input.lower() in ['quitter', 'exit']:
                print("Chat termin√© !")
                break
            
            # Analyser le type de contenu
            meilleur_score = 0
            meilleure_categorie = "incomprehension"
            
            for categorie, reponses in base_reponses.items():
                if categorie != "incomprehension":
                    # Cr√©er une phrase repr√©sentative de la cat√©gorie
                    phrase_type = f"Ceci est li√© √† {categorie}"
                    score = self.similarite_semantique(user_input, phrase_type)
                    
                    if score > meilleur_score:
                        meilleur_score = score
                        meilleure_categorie = categorie
            
            # Seuil minimum pour √©viter les r√©ponses al√©atoires
            if meilleur_score < 0.3:
                meilleure_categorie = "incomprehension"
            
            # Choisir une r√©ponse al√©atoire dans la cat√©gorie
            import random
            reponse = random.choice(base_reponses[meilleure_categorie])
            
            print(f"Mod√®le: {reponse}")
            print(f"         (cat√©gorie: {meilleure_categorie}, confiance: {meilleur_score:.3f})")

    def analyser_semantique_detaillee(self, phrase):
        """
        Analyse s√©mantique pouss√©e d'une phrase
        """
        concepts_references = {
            "logique": "raisonnement logique d√©duction",
            "√©motion": "sentiment √©motion ressenti",
            "action": "faire agir mouvement",
            "description": "√™tre √©tat caract√©ristique",
            "question": "quoi comment pourquoi o√π",
            "science": "physique chimie biologie",
            "philosophie": "existence pens√©e conscience",
            "math√©matiques": "nombre calcul √©quation"
        }
        
        print(f"\nüî¨ Analyse s√©mantique de: '{phrase}'")
        
        scores_concepts = {}
        for concept, mots_cles in concepts_references.items():
            score = self.similarite_semantique(phrase, mots_cles)
            scores_concepts[concept] = score
        
        # Trier par score
        concepts_tries = sorted(scores_concepts.items(), key=lambda x: x[1], reverse=True)
        
        print("üìà Concepts d√©tect√©s :")
        for concept, score in concepts_tries[:5]:
            barre = "‚ñà" * int(score * 20)  # Barre de progression visuelle
            print(f"  {concept:12} : {score:.3f} {barre}")
        
        return concepts_tries[0]  # Retourner le concept principal

    # M√©thode pour utiliser l'analyse
    def mode_analyse(self):
        print("\nüî¨ Mode analyse s√©mantique - Tapez 'quitter' pour arr√™ter")
        
        while True:
            user_input = input("\nPhrase √† analyser: ").strip()
            
            if user_input.lower() in ['quitter', 'exit']:
                break
            
            concept_principal = self.analyser_semantique_detaillee(user_input)
            print(f"üéØ Concept principal d√©tect√©: {concept_principal[0]} ({concept_principal[1]:.3f})")



def main():
    print("ü§ñ IA de Raisonnement Autonome")
    
    import sys
    
    if len(sys.argv) > 1:
        mode = sys.argv[1].lower()
    else:
        mode = input("Mode d'ex√©cution (test/interac/simule/semantique ): ").strip().lower()
    
    if mode == "test":
        modele = BaseModeleFrancais()
        modele.test_comprehension()
    elif mode == "interac":
        modele = BaseModeleFrancais()
        modele.tester_comprehension_interactive()
    elif mode == "simule":
        modele = BaseModeleFrancais()
        modele.chat_simule()
    elif mode == "semantique":
        modele = BaseModeleFrancais()
        modele.mode_analyse()
    else:
        print("Mode non reconnu. Utilisez 'test ou interac ou simule ou semantique'")
        sys.exit(1)

if __name__ == "__main__":
    main()
