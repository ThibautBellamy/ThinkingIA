"""
Test interactif du modÃ¨le d'IA de raisonnement autonome
"""

import torch
import numpy as np
from main_with_trained_model import initialize_components  # Utilise la version avec modÃ¨le entraÃ®nÃ©
from autonomous_reasoning_ai.problem_generators import MathProblemGenerator, PatternProblemGenerator
from autonomous_reasoning_ai.utils.validation import ValidationUtils
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_model_on_problems():
    """Test le modÃ¨le sur diffÃ©rents types de problÃ¨mes"""
    
    print("ðŸ¤– Test Interactif du ModÃ¨le d'IA")
    print("=" * 50)
    
    # Chargement des composants
    print("ðŸ“± Chargement du modÃ¨le...")
    model, problem_generator, trainer = initialize_components()
    device = model.device
    
    # Test sur diffÃ©rentes complexitÃ©s
    complexities = [1, 2, 3, 4, 5]
    domains = ['math']  # Seul le domaine 'math' est disponible actuellement
    
    print(f"\nðŸ§ª Test sur {len(complexities)} niveaux de complexitÃ©")
    print(f"ðŸŽ¯ Domaines disponibles: {domains}")
    
    results_summary = []
    
    for complexity in complexities:
        print(f"\nðŸ“Š === NIVEAU {complexity} ===")
        
        for domain in domains:
            print(f"\nðŸ”¬ Domaine: {domain}")
            
            # GÃ©nÃ©ration de problÃ¨mes de test
            test_problems = problem_generator.generate_batch(
                domain, complexity, batch_size=5
            )
            
            # Ã‰valuation
            eval_result = ValidationUtils.evaluate_model_on_problems(
                model, test_problems, device
            )
            
            # Affichage des rÃ©sultats
            print(f"   ðŸ“ˆ Accuracy: {eval_result['accuracy']:.1%}")
            print(f"   ðŸŽ¯ Reward: {eval_result['total_reward']:.3f}")
            print(f"   ðŸ§  Confiance moy: {np.mean(eval_result['confidence']):.3f}")
            print(f"   ðŸ”„ Consistance moy: {np.mean(eval_result['consistency_scores']):.3f}")
            
            results_summary.append({
                'complexity': complexity,
                'domain': domain,
                'accuracy': eval_result['accuracy'],
                'reward': eval_result['total_reward'],
                'confidence': np.mean(eval_result['confidence']),
                'consistency': np.mean(eval_result['consistency_scores'])
            })
    
    # RÃ©sumÃ© global
    print(f"\nðŸ“‹ === RÃ‰SUMÃ‰ GLOBAL ===")
    print(f"{'Niveau':<8} {'Domaine':<8} {'Accuracy':<10} {'Reward':<8} {'Confiance':<10}")
    print("-" * 50)
    
    for result in results_summary:
        print(f"{result['complexity']:<8} {result['domain']:<8} "
              f"{result['accuracy']:<10.1%} {result['reward']:<8.3f} "
              f"{result['confidence']:<10.3f}")
    
    return results_summary

def test_specific_problem():
    """Test le modÃ¨le sur un problÃ¨me spÃ©cifique"""
    
    print("\nðŸŽ¯ === TEST SPÃ‰CIFIQUE ===")
    
    # Chargement du modÃ¨le
    model, problem_generator, trainer = initialize_components()
    
    # GÃ©nÃ©ration d'un problÃ¨me mathÃ©matique simple
    math_gen = MathProblemGenerator()
    problem = math_gen.generate_addition_problem(complexity=1)
    
    print(f"ðŸ§® ProblÃ¨me mathÃ©matique:")
    print(f"   Input: {problem.input_data}")
    print(f"   Expected: {problem.expected_output}")
    
    # Test du modÃ¨le
    model.eval()
    with torch.no_grad():
        input_tensor = problem.input_data.unsqueeze(0).to(model.device)
        output = model(input_tensor)
        
        print(f"\nðŸ¤– RÃ©sultat du modÃ¨le:")
        print(f"   Solution: {output['solution']}")
        print(f"   Confiance: {output['final_confidence'].mean().item():.3f}")
        print(f"   Consistance: {output['consistency_score'].item():.3f}")
        print(f"   Profondeur: {output['reasoning_depth']}")
        
        # Validation
        if problem.validation_fn:
            is_correct = problem.validation_fn(output['solution'])
            print(f"   âœ… Correct: {is_correct}")
        
        return output

def interactive_menu():
    """Menu interactif pour tester le modÃ¨le"""
    
    while True:
        print(f"\nðŸŽ® === MENU DE TEST ===")
        print("1. ðŸ“Š Test complet (tous niveaux)")
        print("2. ðŸŽ¯ Test problÃ¨me spÃ©cifique")
        print("3. ðŸ§® Test mathÃ©matiques niveau 1")
        print("4. ðŸ”„ Test patterns niveau 2")
        print("5. ðŸ’¬ Poser ma propre question mathÃ©matique")
        print("6. âŒ Quitter")
        
        choice = input("\nChoix (1-6): ").strip()
        
        if choice == "1":
            test_model_on_problems()
        elif choice == "2":
            test_specific_problem()
        elif choice == "3":
            test_math_level_1()
        elif choice == "4":
            test_patterns_level_2()
        elif choice == "5":
            test_custom_math_question()
        elif choice == "6":
            print("ðŸ‘‹ Au revoir!")
            break
        else:
            print("âŒ Choix invalide!")

def test_math_level_1():
    """Test spÃ©cifique sur les maths niveau 1"""
    print("\nðŸ§® === TEST MATHS NIVEAU 1 ===")
    
    model, problem_generator, trainer = initialize_components()
    
    # Test sur 10 problÃ¨mes
    problems = problem_generator.generate_batch('math', 1, batch_size=10)
    
    correct = 0
    total_confidence = 0
    
    for i, problem in enumerate(problems):
        model.eval()
        with torch.no_grad():
            input_tensor = problem.input_data.unsqueeze(0).to(model.device)
            output = model(input_tensor)
            
            confidence = output['final_confidence'].mean().item()
            total_confidence += confidence
            
            if problem.validation_fn and problem.validation_fn(output['solution']):
                correct += 1
                status = "âœ…"
            else:
                status = "âŒ"
            
            print(f"   ProblÃ¨me {i+1}: {status} (Confiance: {confidence:.3f})")
    
    accuracy = correct / len(problems)
    avg_confidence = total_confidence / len(problems)
    
    print(f"\nðŸ“Š RÃ©sultats Maths Niveau 1:")
    print(f"   Accuracy: {accuracy:.1%} ({correct}/{len(problems)})")
    print(f"   Confiance moyenne: {avg_confidence:.3f}")

def test_patterns_level_2():
    """Test spÃ©cifique sur les patterns niveau 2"""
    print("\nðŸ”„ === TEST PATTERNS NIVEAU 2 ===")
    
    model, problem_generator, trainer = initialize_components()
    
    # Test sur patterns niveau 2
    problems = problem_generator.generate_batch('pattern', 2, batch_size=5)
    
    for i, problem in enumerate(problems):
        model.eval()
        with torch.no_grad():
            input_tensor = problem.input_data.unsqueeze(0).to(model.device)
            output = model(input_tensor)
            
            print(f"\nðŸ”„ Pattern {i+1}:")
            print(f"   Input: {problem.input_data.shape}")
            print(f"   Solution: {output['solution'].shape}")
            print(f"   Confiance: {output['final_confidence'].mean().item():.3f}")
            print(f"   Consistance: {output['consistency_score'].item():.3f}")

def test_custom_math_question():
    """Permet Ã  l'utilisateur de poser sa propre question mathÃ©matique"""
    print("\nðŸ’¬ === QUESTION MATHÃ‰MATIQUE PERSONNALISÃ‰E ===")
    print("ðŸ§® Types de questions supportÃ©es:")
    print("   â€¢ Addition: ex. 5 + 3")
    print("   â€¢ Soustraction: ex. 10 - 4") 
    print("   â€¢ Multiplication: ex. 6 * 7")
    print("   â€¢ Questions simples avec nombres entiers")
    
    # Charger le modÃ¨le
    model, problem_generator, trainer = initialize_components()
    
    while True:
        print("\n" + "="*50)
        question = input("ðŸ¤” Votre question mathÃ©matique (ou 'quit' pour quitter): ").strip()
        
        if question.lower() in ['quit', 'quitter', 'q', 'exit']:
            print("ðŸ‘‹ Retour au menu principal")
            break
            
        if not question:
            print("âŒ Veuillez entrer une question!")
            continue
            
        try:
            # Parse la question mathÃ©matique
            result = parse_and_solve_math_question(question, model)
            
            if result:
                print(f"\nðŸ¤– === RÃ‰PONSE DU MODÃˆLE ===")
                print(f"   ðŸ“ Question: {question}")
                print(f"   ðŸ”¢ RÃ©ponse calculÃ©e: {result['calculated_answer']}")
                print(f"   ðŸ¤– RÃ©ponse IA: {result['ai_response']:.3f}")
                print(f"   âœ… Correct: {'Oui' if result['is_correct'] else 'Non'}")
                print(f"   ðŸŽ¯ Confiance: {result['confidence']:.3f}")
                print(f"   ðŸ§  Consistance: {result['consistency']:.3f}")
                print(f"   ðŸ”„ Profondeur raisonnement: {result['reasoning_depth']}")
                
                if result['is_correct']:
                    print("   ðŸŽ‰ Excellente rÃ©ponse!")
                else:
                    print(f"   ðŸ“š La bonne rÃ©ponse Ã©tait: {result['calculated_answer']}")
            else:
                print("âŒ Format de question non reconnu!")
                print("ðŸ’¡ Essayez: '5 + 3', '10 - 2', '4 * 6', etc.")
                
        except Exception as e:
            print(f"âŒ Erreur lors du traitement: {e}")
            print("ðŸ’¡ VÃ©rifiez le format de votre question")

def parse_and_solve_math_question(question, model):
    """Parse une question mathÃ©matique et la rÃ©sout avec le modÃ¨le"""
    import re
    
    # Nettoyer la question
    question = question.replace(" ", "").lower()
    
    # Patterns pour diffÃ©rents types d'opÃ©rations
    patterns = [
        (r'(\d+)\+(\d+)', lambda a, b: int(a) + int(b), 'addition'),
        (r'(\d+)\-(\d+)', lambda a, b: int(a) - int(b), 'soustraction'),
        (r'(\d+)\*(\d+)', lambda a, b: int(a) * int(b), 'multiplication'),
        (r'(\d+)x(\d+)', lambda a, b: int(a) * int(b), 'multiplication'),
    ]
    
    for pattern, calc_func, operation_type in patterns:
        match = re.match(pattern, question)
        if match:
            num1, num2 = match.groups()
            
            # Calcul de la vraie rÃ©ponse
            calculated_answer = calc_func(num1, num2)
            
            # CrÃ©ation d'un problÃ¨me pour le modÃ¨le
            problem_tensor = create_math_problem_tensor(int(num1), int(num2), operation_type)
            
            # Test avec le modÃ¨le
            model.eval()
            with torch.no_grad():
                input_tensor = problem_tensor.unsqueeze(0).to(model.device)
                output = model(input_tensor)
                
                # Extraction de la rÃ©ponse du modÃ¨le
                ai_response = output['solution'].mean().item()
                confidence = output['final_confidence'].mean().item()
                consistency = output['consistency_score'].item()
                reasoning_depth = output['reasoning_depth']
                
                # VÃ©rification si c'est correct (tolÃ©rance de 0.1)
                is_correct = abs(ai_response - calculated_answer) < 0.1
                
                return {
                    'calculated_answer': calculated_answer,
                    'ai_response': ai_response,
                    'is_correct': is_correct,
                    'confidence': confidence,
                    'consistency': consistency,
                    'reasoning_depth': reasoning_depth,
                    'operation_type': operation_type
                }
    
    return None

def create_math_problem_tensor(num1, num2, operation_type):
    """CrÃ©e un tenseur d'entrÃ©e pour un problÃ¨me mathÃ©matique"""
    # Utiliser le mÃªme format que le gÃ©nÃ©rateur : [num1, num2, operation_code]
    operation_codes = {
        'addition': 0.0,        # MÃªme encodage que le gÃ©nÃ©rateur
        'soustraction': 1.0, 
        'multiplication': 2.0,
        'division': 3.0
    }
    
    # Pas de normalisation - utiliser les valeurs directes comme le gÃ©nÃ©rateur
    op_code = operation_codes.get(operation_type, 0.0)
    
    # CrÃ©ation du tenseur d'entrÃ©e (mÃªme format que le gÃ©nÃ©rateur)
    input_data = torch.zeros(64)  # Dimension d'entrÃ©e du modÃ¨le
    input_data[0] = float(num1)  # Pas de normalisation
    input_data[1] = float(num2)  # Pas de normalisation
    input_data[2] = op_code      # Code d'opÃ©ration
    # Note: Pas de rÃ©sultat attendu - le modÃ¨le doit le calculer !
    
    return input_data

if __name__ == "__main__":
    try:
        interactive_menu()
    except KeyboardInterrupt:
        print("\nðŸ‘‹ Test interrompu par l'utilisateur")
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        import traceback
        traceback.print_exc()
