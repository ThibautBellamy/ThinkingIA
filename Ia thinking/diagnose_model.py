"""
Script de diagnostic du modÃ¨le entraÃ®nÃ©
"""

import torch
import os
import numpy as np
from main_with_trained_model import initialize_components  # Utilise la version avec modÃ¨le entraÃ®nÃ©
from autonomous_reasoning_ai.utils.validation import ValidationUtils

def diagnose_model():
    """Diagnostique approfondi du modÃ¨le"""
    print("ğŸ” === DIAGNOSTIC DU MODÃˆLE ===")
    print("=" * 50)
    
    # 1. VÃ©rification des fichiers de modÃ¨le
    print("\nğŸ“ 1. VÃ©rification des fichiers...")
    model_path = r'results\autonomous_reasoning_v1_20250902_175324\best_model.pt'
    
    if os.path.exists(model_path):
        print("âœ… Fichier de modÃ¨le trouvÃ©")
        checkpoint = torch.load(model_path, map_location='cpu')
        
        print(f"ğŸ“Š Informations du checkpoint:")
        for key, value in checkpoint.items():
            if key != 'model_state_dict':
                print(f"   {key}: {value}")
        
        if 'model_state_dict' in checkpoint:
            print(f"ğŸ§  Nombre de paramÃ¨tres sauvegardÃ©s: {len(checkpoint['model_state_dict'])}")
        else:
            print("âŒ Ã‰tat du modÃ¨le manquant dans le checkpoint!")
            return
    else:
        print(f"âŒ Fichier de modÃ¨le non trouvÃ©: {model_path}")
        return
    
    # 2. Chargement et test du modÃ¨le
    print("\nğŸ¤– 2. Chargement du modÃ¨le...")
    try:
        model, problem_generator, trainer = initialize_components()
        print("âœ… ModÃ¨le chargÃ© avec succÃ¨s")
        print(f"ğŸ–¥ï¸ Device: {model.device}")
        print(f"ğŸ§  ParamÃ¨tres totaux: {sum(p.numel() for p in model.parameters())}")
        print(f"ğŸ“Š ParamÃ¨tres entraÃ®nables: {sum(p.numel() for p in model.parameters() if p.requires_grad)}")
        
    except Exception as e:
        print(f"âŒ Erreur lors du chargement: {e}")
        return
    
    # 3. Test de forward pass simple
    print("\nğŸ§ª 3. Test de forward pass...")
    try:
        # CrÃ©er un tensor de test simple
        test_input = torch.zeros(1, 64, device=model.device)
        test_input[0, 0] = 5.0  # Premier nombre
        test_input[0, 1] = 3.0  # DeuxiÃ¨me nombre
        test_input[0, 2] = 0.0  # OpÃ©ration (addition)
        
        with torch.no_grad():
            output = model(test_input)
        
        print(f"âœ… Forward pass rÃ©ussi")
        print(f"ğŸ“¤ Input shape: {test_input.shape}")
        print(f"ğŸ“¥ Output shape: {output.shape}")
        print(f"ğŸ”¢ Output value: {output.item():.6f}")
        print(f"ğŸ¯ Expected (5+3): 8")
        print(f"â“ Proche du rÃ©sultat attendu: {'Oui' if abs(output.item() - 8) < 1 else 'Non'}")
        
    except Exception as e:
        print(f"âŒ Erreur lors du forward pass: {e}")
        return
    
    # 4. Test avec diffÃ©rents problÃ¨mes simples
    print("\nğŸ§® 4. Test sur problÃ¨mes mathÃ©matiques simples...")
    test_cases = [
        (2, 3, 0, 5),   # 2+3=5
        (10, 4, 1, 6),  # 10-4=6
        (3, 4, 2, 12),  # 3*4=12
        (8, 2, 3, 4),   # 8/2=4
    ]
    
    operations = ["addition", "soustraction", "multiplication", "division"]
    
    for i, (a, b, op, expected) in enumerate(test_cases):
        test_input = torch.zeros(1, 64, device=model.device)
        test_input[0, 0] = float(a)
        test_input[0, 1] = float(b)
        test_input[0, 2] = float(op)
        
        with torch.no_grad():
            output = model(test_input)
        
        result = output.item()
        correct = abs(result - expected) < 0.5
        
        print(f"   {operations[op]}: {a} {['+', '-', '*', '/'][op]} {b} = {expected}")
        print(f"   ğŸ¤– ModÃ¨le: {result:.3f} {'âœ…' if correct else 'âŒ'}")
    
    # 5. Test avec le gÃ©nÃ©rateur de problÃ¨mes
    print("\nğŸ² 5. Test avec gÃ©nÃ©rateur de problÃ¨mes...")
    try:
        problems = problem_generator.generate_batch('math', 1, batch_size=3)
        validator = ValidationUtils()
        
        for i, problem in enumerate(problems):
            with torch.no_grad():
                output = model(problem.input_data.unsqueeze(0))
            
            result = output.item()
            is_correct = problem.validation_fn(result)
            
            print(f"   ProblÃ¨me {i+1}:")
            print(f"   ğŸ“ MÃ©tadonnÃ©es: {problem.metadata}")
            print(f"   ğŸ¤– RÃ©ponse modÃ¨le: {result:.3f}")
            print(f"   âœ… Correct: {'Oui' if is_correct else 'Non'}")
            
    except Exception as e:
        print(f"âŒ Erreur avec le gÃ©nÃ©rateur: {e}")
    
    # 6. Analyse des poids du modÃ¨le
    print("\nâš–ï¸ 6. Analyse des poids...")
    total_params = 0
    zero_params = 0
    
    for name, param in model.named_parameters():
        total_params += param.numel()
        zero_params += (param.abs() < 1e-6).sum().item()
        
        if param.numel() < 20:  # Afficher seulement les petites couches
            print(f"   {name}: shape={param.shape}, mean={param.mean().item():.6f}, std={param.std().item():.6f}")
    
    print(f"\nğŸ“Š Statistiques globales:")
    print(f"   Total paramÃ¨tres: {total_params}")
    print(f"   ParamÃ¨tres quasi-nuls: {zero_params} ({100*zero_params/total_params:.1f}%)")
    
    # 7. Recommandations
    print("\nğŸ’¡ 7. Recommandations:")
    
    if zero_params / total_params > 0.9:
        print("   âš ï¸ Trop de paramÃ¨tres sont quasi-nuls - le modÃ¨le n'a peut-Ãªtre pas appris")
        print("   ğŸ”§ Solution: Relancer l'entraÃ®nement avec un learning rate plus Ã©levÃ©")
    
    # Test si le modÃ¨le donne toujours la mÃªme sortie
    outputs = []
    for _ in range(5):
        test_input = torch.randn(1, 64, device=model.device)
        with torch.no_grad():
            output = model(test_input)
        outputs.append(output.item())
    
    output_variance = np.var(outputs)
    if output_variance < 1e-6:
        print("   âš ï¸ Le modÃ¨le donne toujours la mÃªme sortie - il n'a pas appris la diversitÃ©")
        print("   ğŸ”§ Solution: VÃ©rifier l'architecture et relancer l'entraÃ®nement")
    else:
        print(f"   âœ… Variance des sorties: {output_variance:.6f} (bon signe)")
    
    print("\nğŸ Diagnostic terminÃ©!")

if __name__ == "__main__":
    diagnose_model()
