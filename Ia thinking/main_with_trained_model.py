"""
Version modifi√©e de main.py pour charger automatiquement le mod√®le entra√Æn√© le plus r√©cent
"""

import os
import torch
import logging
import shutil
import glob
from datetime import datetime
from autonomous_reasoning_ai.main import *
from autonomous_reasoning_ai.config import config
from autonomous_reasoning_ai.training.autonomous_trainer import AutonomousLearningTrainer

# Chemin fixe pour le mod√®le actuel
CURRENT_MODEL_PATH = "current_best_model.pt"

def find_latest_model():
    """Trouve le mod√®le entra√Æn√© le plus r√©cent dans les dossiers de r√©sultats"""
    results_dir = "results"
    
    if not os.path.exists(results_dir):
        return None
    
    # Chercher tous les fichiers best_model.pt dans les sous-dossiers
    model_files = glob.glob(os.path.join(results_dir, "*", "best_model.pt"))
    
    if not model_files:
        return None
    
    # Trier par date de modification (le plus r√©cent en dernier)
    model_files.sort(key=lambda x: os.path.getmtime(x))
    
    return model_files[-1]  # Le plus r√©cent

def copy_latest_model_to_current():
    """Copie le mod√®le le plus r√©cent vers le chemin fixe"""
    logger = logging.getLogger(__name__)
    
    latest_model = find_latest_model()
    
    if latest_model is None:
        logger.warning("‚ùå Aucun mod√®le entra√Æn√© trouv√© dans le dossier results/")
        return False
    
    try:
        # Copier le mod√®le vers le chemin fixe
        shutil.copy2(latest_model, CURRENT_MODEL_PATH)
        
        # Obtenir les infos du mod√®le source
        model_dir = os.path.dirname(latest_model)
        experiment_name = os.path.basename(model_dir)
        modification_time = datetime.fromtimestamp(os.path.getmtime(latest_model))
        
        logger.info(f"‚úÖ Mod√®le copi√© avec succ√®s!")
        logger.info(f"üìÅ Source: {latest_model}")
        logger.info(f"üéØ Destination: {CURRENT_MODEL_PATH}")
        logger.info(f"üß™ Exp√©rience: {experiment_name}")
        logger.info(f"üìÖ Derni√®re modification: {modification_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la copie du mod√®le: {e}")
        return False

def initialize_components_with_latest_model():
    """Initialise tous les composants du syst√®me avec le mod√®le entra√Æn√© le plus r√©cent"""
    logger = logging.getLogger(__name__)
    logger.info("Initialisation des composants avec mod√®le le plus r√©cent...")
    
    # √âtape 1: Copier le mod√®le le plus r√©cent
    logger.info("üîç Recherche du mod√®le le plus r√©cent...")
    model_copied = copy_latest_model_to_current()
    
    # Cr√©ation du g√©n√©rateur de probl√®mes
    problem_generator = ProblemGenerator()
    problem_generator.register_generator("math", MathProblemGenerator())
    
    # Cr√©ation du mod√®le
    model = AutonomousReasoningCore()
    model = model.to(config.model.device)
    
    # Chargement du mod√®le entra√Æn√©
    if model_copied and os.path.exists(CURRENT_MODEL_PATH):
        logger.info(f"üìÇ Chargement du mod√®le depuis: {CURRENT_MODEL_PATH}")
        try:
            checkpoint = torch.load(CURRENT_MODEL_PATH, map_location=config.model.device)
            
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                # Checkpoint complet avec m√©tadonn√©es
                model.load_state_dict(checkpoint['model_state_dict'])
                logger.info("‚úÖ Mod√®le charg√© avec succ√®s (checkpoint complet)!")
                
                # Afficher les m√©tadonn√©es si disponibles
                if 'epoch' in checkpoint:
                    logger.info(f"üìä √âpoque: {checkpoint['epoch']}")
                if 'loss' in checkpoint:
                    logger.info(f"üìâ Loss: {checkpoint['loss']:.6f}")
                if 'accuracy' in checkpoint:
                    logger.info(f"üéØ Accuracy: {checkpoint['accuracy']:.4f}")
                if 'reward' in checkpoint:
                    logger.info(f"üèÜ Reward: {checkpoint['reward']:.6f}")
            else:
                # Seulement les poids du mod√®le
                model.load_state_dict(checkpoint)
                logger.info("‚úÖ Poids du mod√®le charg√©s avec succ√®s!")
                
            # Passer en mode √©valuation
            model.eval()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
            logger.warning("üîÑ Utilisation du mod√®le non entra√Æn√©")
    else:
        logger.warning(f"‚ùå Aucun mod√®le trouv√©")
        logger.warning("üîÑ Utilisation du mod√®le non entra√Æn√©")
    
    # Cr√©ation du trainer (pour compatibilit√©)
    trainer = AutonomousLearningTrainer(model, problem_generator)
    
    return model, problem_generator, trainer

# Remplacer la fonction d'origine pour les tests
initialize_components = initialize_components_with_latest_model
